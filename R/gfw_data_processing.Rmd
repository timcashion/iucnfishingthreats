---
title: "gfw_processing"
author: "Tim"
date: "June 27, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source(here::here("R", "common_fxns.R"))

packages <- c("tidyverse", 
              "maptools", 
              "rgdal", 
              "sf", 
              "wesanderson",
              "sp",
              "raster")
ipak(packages)
theme_set(theme_classic())
```

GFW Readme file:
"Fishing Effort

Daily Fishing Effort and Vessel Presence at 100th Degree Resolution by Flag State and GearType, 2012-2016

Fishing effort and vessel presence data is avaialbe in the following formats:
 - BigQuery Tables
 - CSVs
 - Geotiff Rasters in Google Earth Engine

Links to these data are available at Global Fishing Watch's community page (https://globalfishingwatch.force.com/gfw/s/data_download).

For additional information about these results, see the associated journal article: D.A. Kroodsma, J. Mayorga, T. Hochberg, N.A. Miller, K. Boerder, F. Ferretti, A. Wilson, B. Bergman, T.D. White, B.A. Block, P. Woods, B. Sullivan, C. Costello, and B. Worm. "Tracking the global footprint of fisheries." Science 361.6378 (2018). (http://science.sciencemag.org/cgi/doi/10.1126/science.aao1118)

For updates, links to example code, and more, visit:

 - Global Fishing Watch R&D Site (globalfishingwatch.io/global-footprint-of-fisheries.html)
 - GitHub Repo for Tracking the Global Footprint of Fisheries (GitHub.com/globalfishingwatch/tracking-global-footprint-of-fisheries)

Description: Fishing effort and vessel presence is binned into grid cells 0.01 degrees on a side, and measured in units of hours. The time is calculated by assigning an amount of time to each AIS detection (which is half the time to the previous plus half the time to the next AIS position), and then summing all positions in each grid cell. Data is based on fishing detections of >70,000 unique AIS devices on fishing vessels. Fishing vessels are identified via a neural network classifier and vessel registry databases. The neural net classifies fishing vessels into six categories:

 - drifting_longlines: drifting longlines
 - purse_seines: purse seines, both pelagic and demersal
 - trawlers: trawlers, all types
 - fixed_gear: a category that includes set longlines, set gillnets, and pots and traps 
 - squid_jigger: squid jiggers, mostly large industrial pelagic operating vessels
 - other_fishing: a combination of vessels of unknown fishing gear and other, less common gears such as trollers or pole and line 


Table Schema
 - date: a string in format “YYYY-MM-DD” 
 - lat_bin: the southern edge of the grid cell, in 100ths of a degree -- 101 is the grid cell with a southern edge at 1.01 degrees north
 - lon_bin: the western edge of the grid cell, in 100ths of a degree -- 101 is the grid cell with a western edge at 1.01 degrees east
 - flag: the flag state of the fishing effort, in iso3 value
 - geartype: see our description of geartpyes
 - vessel_hours: hours that vessels of this geartype and flag were present in this gridcell on this day
 - fishing_hours: hours that vessels of this geartype and flag were fishing in this gridcell on this day
 - mmsi_present: number of mmsi of this flag state and geartype that visited this grid cell on this day 	"


```{r map-setup}
pal <- wes_palette(name = "Zissou1", n=100, type = c("continuous"))
#Load it!
World <- readOGR(file.path(dir_spatial,"ne_10m_coastline/ne_10m_coastline.shp"))

Forty_World<- fortify(World)

base_map <- ggplot() +
  geom_path(data = Forty_World, aes(x = long,
                                    y = lat,
                                    group = group
  ),
  color = "black",
  size = 0.25) +
  theme_classic() + 
  labs(list(title = "",
            x = "Longitude",
            y = "Latitude")) +
  #scale_fill_gradientn(colours = pal) +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  labs(fill="") + 
  NULL 



```

```{r gfw-theme}
theme_gfw_paper <-  theme(text = element_text(family="Arial", face="bold", size=12),
        axis.text.x = element_text(size = 12, colour = "black"),
        axis.text.y = element_text(size = 12, colour = "black"),
        axis.line.x = element_line(colour = "black", size = .5),
        axis.line.y = element_line(colour = "black", size = .5),
        legend.position = "bottom",
        axis.title.y = element_text(size = 12, margin=margin(0,15,0,0)),
        axis.title.x = element_text(size = 12, margin=margin(15,0,0,0)),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"),
        plot.margin = unit(c(1,1,1,1), "cm")
        )

cont_fill = 'white'#'grey30' #'grey80'
back_fill =  'white'#'#202A50' #'black' #'#1F2A4F'
cont_color = 'grey60'#'grey30'
#color_grad = c( "#414487", "#2A788E", "#22A884", "#7AD151","#FDE725","#FFC04C")
color_grad = c("#C6DBEF", "#9ECAE1", "#6BAED6","#4292C6" ,"#2171B5", "#084594") #blues
```


Attempting to draw similar maps to SAU data with GFW data. Use known fishing effort data to map out other indicators of industrial threats to these species. 

```{r compile-gfw-data, eval=FALSE}

cell_size <- "01"
dir_spatial_csvs <- "../spatial/csvs"
effort_dir <- "../data/fishing_effort/daily_csvs"
effort_files <- list.files("../data/fishing_effort/daily_csvs/")
effort_files <- effort_files[grepl(effort_files, pattern="2016")]
cell_ids <- read.csv(file.path(dir_spatial_csvs , paste("cell_ids_", cell_size,".txt", sep="")), header=T, col.names = c("cell_id", "lon", "lat"))

# lat_bin: the southern edge of the grid cell, in 100ths of a degree -- 101 is the grid cell with a southern edge at 1.01 degrees north
# lon_bin: the western edge of the grid cell, in 100ths of a degree -- 101 is the grid cell with a western edge at 1.01 degrees east
gfw_2016 <- tibble()
s <- Sys.time()
#cols_to_keep <- c("geartype", "flag")

#res parameter gives a rough cell resolution but it might be off by a factor of 2. i.e., 0.25 gives cells of 0.5 by 0.5 
summarize_gfw <- function(file, cell_res="all", cols_to_keep=NA) {
  dat <- data.table::fread(file.path(effort_dir,file))
  #dat <- read_csv(file.path(effort_dir,file), col_types = "Dddccddd")

  #df <- convert_to_centroid(dat)
  if(cell_res=="all"){
    df <- dat
    df$sau_lon <- floor((df$lon)/0.5) * 0.5 #plyr::round_any(df$lon, 0.25, f=round) #Fit GFW grid to coarser SAU grid
    df$sau_lat<- floor((df$lat)/0.5) * 0.5 #plyr::round_any(df$lat, 0.25, f=round) #Fit GFW grid to coarser SAU grid 
    df <- df %>%
      group_by(date, geartype, lat_bin, lon_bin, lat, lon, sau_lon, sau_lat) %>% 
      summarize(vessel_hours = sum(vessel_hours),
                fishing_hours = sum(fishing_hours),
                mmsi_present = sum(mmsi_present))
  }else if(cell_res==0.5){
    df <- convert_to_centroid(dat)
    df <- convert_to_sau(df)
    df <- df %>%
          group_by(date, lat, lon, geartype) %>% 
          summarize(vessel_hours = sum(vessel_hours),
                    fishing_hours = sum(fishing_hours))
  } else {
    res <- cell_res/2
    df <- convert_to_centroid(dat)
    df <- convert_to_new_grid(df, res)
    df <- df %>%
          group_by(date, lat, lon, geartype) %>% 
          summarize(vessel_hours = sum(vessel_hours),
                    fishing_hours = sum(fishing_hours))
  }
  return(df)
}


# cell_size <- "05"
file <- effort_files[100]
dat <- data.table::fread(file.path(effort_dir,file))
summarize_gfw(file, cell_res=as.numeric(cell_size)/10)



#Pretty sure mclapply is faster. With a test of the first 10 it was faster by .5 seconds (~18%)
s <- Sys.time()
gfw_list <- parallel::mclapply(effort_files, summarize_gfw, cell_res=as.numeric(cell_size)/10, cols_to_keep=NA)
# gfw_frame <- bind_rows(gfw_list)
# gfw_frame1 <- data.table::rbindlist(gfw_list[1:(floor(length(gfw_list)/10))])
gfw_frame <- data.table::rbindlist(gfw_list)

e <- Sys.time()
e-s #Got it down to 5.38 minutes for 2016 effort files
#cell_size <- "001"
write_csv(gfw_frame, file.path(dir_spatial_csvs, paste("gfw_2016_",cell_size , ".csv", sep="")))

```

```{r gfw-2016-fishing-effort}
cell_size <- "01"
dir_spatial_csvs <- "../spatial/csvs"

gfw_frame <- data.table::fread(file.path(dir_spatial_csvs, paste("gfw_2016_",cell_size , ".csv", sep="")))
gfw_2016 <- gfw_frame %>% 
  ungroup() %>% 
  group_by(lat, lon) %>% 
  summarize(vessel_hours = sum(vessel_hours),
                    fishing_hours = sum(fishing_hours))

gg <- base_map +
  geom_tile(data=gfw_2016, aes(x=lon, y=lat, fill=log10(fishing_hours))) +
  scale_fill_viridis_c("Fishing hours", na.value = NA, limits = c(1, 5), 
                       breaks=c(seq(1,5,length.out = 4)),
                       labels = c('1','10', '100','> 1000' ), 
                       direction = -1)+
    coord_sf(datum = NA) +
    theme_gfw_paper +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks = element_blank(),
          axis.line = element_blank(),
          panel.background = element_rect(color = NA, fill = back_fill),
          #legend.position = 'none',
          legend.direction="horizontal",
          plot.margin=unit(c(0,-0.5,-0.5,-0.5), 'cm'),
          legend.text = element_text(size = 6, family = 'Times New Roman'),
          legend.title = element_text(size = 7, family = 'Times New Roman')) + 
  NULL
gg


```



```{r data-iucn}


dir_data <- "../data"
dir_rasters <- "../spatial/spp_rasters"
risk_codes <- read.csv(file.path(dir_data, "risk_code_lookup.csv"), stringsAsFactors = F)
spat_files <- list.files(file.path(paste(dir_rasters, "_", cell_size, sep="")))
raster_read <- function(filename){
  id <- gsub(filename, pattern="iucn_sid_", replacement = "")
  id <- gsub(id, pattern=".csv", replacement = "")
  spp_rast <- data.table::fread(file.path(paste(dir_rasters, "_", cell_size, sep=""), filename))
  if(nrow(spp_rast)>0){
    spp_rast$iucn_sid <- as.numeric(id)
    return(spp_rast)
  }
}
spat_list <- parallel::mclapply(spat_files, raster_read)
spat_list <- data.table::rbindlist(spat_list[2:6720])

cell_ids <- read.csv(file.path(dir_spatial_csvs , paste("cell_ids_", cell_size,".txt", sep="")), header=T, col.names = c("cell_id", "lon", "lat"))
cell_id_area <- data.table::fread(file.path(dir_spatial_csvs, paste("cell_id_area_", cell_size,".txt", sep="")))

spat_data <- spat_list %>% 
  left_join(cell_ids, by="cell_id") %>%
  mutate(category = if_else(is.na(rgn_category), global_category, rgn_category)) %>% 
  left_join(risk_codes %>% dplyr::select(-c(category)), by=c("category"="code"))
gc()
```


```{r gfw-gear-type}

dir_output <- "../output"
#Let's start with trawlers:
gear <- "trawlers"
gfw_2016 <- gfw_frame
gfw_2016$geartype <- gsub(gfw_2016$geartype, pattern="_", replacement=" ")
gfw_2016$geartype <- gsub(gfw_2016$geartype, pattern="purse seines", replacement="purse seine")


gfw_gear_types <- unique(gfw_2016$geartype)
text_threats <- read.csv(file.path(dir_data, "narrative_threats_output_tidy.csv"))
iucn_gear_types <- unique(text_threats$super_code)
gear_types <- iucn_gear_types[grep(iucn_gear_types, pattern=paste(gfw_gear_types, collapse="|"))]

gear <- "longline"


for(gear in gear_types){
  gear_species <- text_threats %>%
    filter(super_code %in% gear) %>% 
    dplyr::select(iucn_sid) %>% 
    unique()
  effort_dat <- gfw_2016 %>% 
    filter(grepl(geartype, pattern=gear)) %>% 
    group_by(lon, lat) %>% 
    summarize(fishing_hours = sum(fishing_hours)) %>% 
    ungroup() %>% 
    filter(fishing_hours > 0)
  threat_dat <- spat_data %>% 
    filter(iucn_sid %in% gear_species$iucn_sid)  %>% 
    group_by(lon, lat) %>% 
    summarize(n = sum(presence, na.rm = T),
              weighted_score = sum(cat_score, na.rm = T)) %>% 
    ungroup()
  write_csv(effort_dat, file.path(dir_output, paste(gear, "_GFW_effort_", cell_size, ".csv", sep="")))
  write_csv(threat_dat, file.path(dir_output, paste(gear, "_IUCN_threat_", cell_size, ".csv", sep="")))
}


```

```

